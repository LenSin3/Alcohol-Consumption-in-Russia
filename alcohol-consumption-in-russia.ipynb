{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "partial-triple",
   "metadata": {},
   "source": [
    "# Alcohol Consumption in Russia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-stanley",
   "metadata": {},
   "source": [
    "![Alcoholic Beverages in Russia](images/drinks.png)\n",
    "            Source: [The Russian alcohol market: a heady cocktail](http://www.food-exhibitions.com/Market-Insights/Russia/The-Russian-alcohol-market)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-exhibit",
   "metadata": {},
   "source": [
    "## Project Motivation\n",
    "\n",
    "A fictitious company owns a chain of stores across Russia that sell a variety of types of alcohol. The company recently ran a wine promotion in Saint Petersburg that was very successful. Due to the cost to the business, it isnâ€™t possible to run the promotion in all regions. The marketing team would like to target 10 other regions that have similar buying habits to Saint Petersburg where they would expect the promotion to be similarly successful and need help determining which regions they should select.\n",
    "\n",
    "![Regions in Russia](images/regions.png)\n",
    "        Source: [Outline of Russia](https://en.wikipedia.org/wiki/Outline_of_Russia)\n",
    "        \n",
    "This project aims to use machine learning algorithm to recommend, at least 10 regions with alcohol buying habits similar to Saint Petersburg. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-atlantic",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The data used in this project is obtained from [Datacamp's Career Hub repository](https://github.com/datacamp/careerhub-data) on GitHub. It contains 7 variables as see in the description below:\n",
    "\n",
    "![Description of dataset](images/data_description.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-washer",
   "metadata": {},
   "source": [
    "## Analysis Plan\n",
    "\n",
    "Based on the ask of the project, the problem is best solved using an unsupervied machine learning algorithm that could best cluster regions based on wine sales in Saint Petersburg. Selection of this algorithm will be done in subsequent sections.\n",
    "\n",
    "The following steps will be followed:\n",
    "\n",
    "- Perform Exploratory Data Analysis to identify patters and draw insights from the data.\n",
    "- Select a suitable unsupervised machine learning algorithm based on problem to solve and information from the exploratory data analysis.\n",
    "- Discuss model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-norway",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "This section will explore the data to discover trends and insights. It will be done by creating plots of features against their values. The following steps will be implemented:\n",
    "\n",
    "- Read data\n",
    "- Check for data quality issues.\n",
    "- Clean and transform data into a suitable format for exploration.\n",
    "- Data Visualization to observe patterns and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faced-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.19041-SP0\n",
      "Python 3.6.12 |Anaconda, Inc.| (default, Sep  9 2020, 00:29:25) [MSC v.1916 64 bit (AMD64)]\n",
      "Numpy 1.19.2\n",
      "Matplotlib 3.3.2\n",
      "Pandas 1.1.5\n",
      "Seaborn 0.11.1\n",
      "Scipy 1.5.2\n",
      "Scikit -Learn 0.23.2\n"
     ]
    }
   ],
   "source": [
    "# import system and exploratory analysis modules\n",
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy as np; print(\"Numpy\", np.__version__)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt; print(\"Matplotlib\", matplotlib.__version__)\n",
    "import pandas as pd; print(\"Pandas\", pd.__version__)\n",
    "import seaborn as sns; print(\"Seaborn\", sns.__version__)\n",
    "import scipy; print(\"Scipy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit -Learn\", sklearn.__version__)\n",
    "import funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set theme for seaborn\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-instruction",
   "metadata": {},
   "source": [
    "### Read and check data for quality issues\n",
    "\n",
    "A function us created to do the following:\n",
    "- Read the data\n",
    "- Drop duplicates\n",
    "- Create a list of feature names\n",
    "- Create a containing data types and nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "genuine-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to read data, check for nulls and drop duplicates\n",
    "# def read_data(data_path):\n",
    "#     # read data\n",
    "#     print(\"Reading Alcohol Consumption in Russia dataset\\n\")\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     # make a copy of dataframe\n",
    "#     print(\"Making a copy of the dataframe\\n\")\n",
    "#     df_1 = df.copy()\n",
    "#     # drop duplicates\n",
    "#     df_final = df_1.drop_duplicates()\n",
    "#     # extract feature names\n",
    "#     df_cols = df_final.columns.tolist()\n",
    "#     print(\"Data consists of:\\n\")\n",
    "#     print(\"...........................\\n\")\n",
    "#     print(\"Rows: {}\\n\".format(len(df_final)))\n",
    "#     print(\"Columns: {}\\n\".format(len(df_cols)))\n",
    "#     print(\"...........................\\n\")\n",
    "#     # empty list to hold data types, non nulss count, nulss count, percentage of nulls in a column,\\\n",
    "#     # percentage of column nulls in datafram\n",
    "#     data_types = []\n",
    "#     non_nulls = []\n",
    "#     nulls = []\n",
    "#     null_column_percent = []\n",
    "#     null_df_percent = []\n",
    "    \n",
    "#     # loop through columns and capture the variables above\n",
    "#     print(\"Extracting count and percentages of nulls and non nulls\")\n",
    "#     for col in df_cols:\n",
    "        \n",
    "#         # extract null count\n",
    "#         null_count = df_final[col].isna().sum()\n",
    "#         nulls.append(null_count)\n",
    "        \n",
    "#         # extract non null count\n",
    "#         non_null_count = len(df_final) - null_count\n",
    "#         non_nulls.append(non_null_count)\n",
    "        \n",
    "#         # extract % of null in column\n",
    "#         col_null_perc = 100 * null_count/len(df_final)\n",
    "#         null_column_percent.append(col_null_perc)\n",
    "        \n",
    "#         # extract % of nulls out of total nulls in dataframe\n",
    "#         df_null_perc = 100 * null_count/df_final.isna().sum().sum()\n",
    "#         null_df_percent.append(df_null_perc)\n",
    "        \n",
    "#         # capture data types\n",
    "#         data_types.append(df_final[col].dtypes) \n",
    "        \n",
    "#     # create zipped list with column names, data_types, nulls and non nulls\n",
    "#     lst_data = list(zip(df_cols, data_types, non_nulls, nulls, null_column_percent, null_df_percent))\n",
    "#     # create dataframe of zipped list\n",
    "#     df_zipped = pd.DataFrame(lst_data, columns = ['Feature', 'DataType', 'CountOfNonNulls', 'CountOfNulls',\\\n",
    "#                                                  'PercentOfNullsIinColumn', 'PercentOfNullsInData'])\n",
    "#     return df_final, df_cols, df_zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amino-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'alcohol-consumption-in-russia.csv'\n",
    "# df, features, df_QA = read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "asian-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a copy of the dataframe\n",
      "\n",
      "Data consists of:\n",
      "\n",
      "...........................\n",
      "\n",
      "Rows: 1615\n",
      "\n",
      "Columns: 7\n",
      "\n",
      "...........................\n",
      "\n",
      "Extracting count and percentages of nulls and non nulls\n"
     ]
    }
   ],
   "source": [
    "df, df_cols, df_nulls = funcs.read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "published-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>wine</th>\n",
       "      <th>beer</th>\n",
       "      <th>vodka</th>\n",
       "      <th>champagne</th>\n",
       "      <th>brandy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>Republic of Adygea</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>Amur Oblast</td>\n",
       "      <td>2.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>Arkhangelsk Oblast</td>\n",
       "      <td>4.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>Astrakhan Oblast</td>\n",
       "      <td>2.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year              region  wine  beer  vodka  champagne  brandy\n",
       "0  1998  Republic of Adygea   1.9   8.8    3.4        0.3     0.1\n",
       "1  1998          Altai Krai   3.3  19.2   11.3        1.1     0.1\n",
       "2  1998         Amur Oblast   2.1  21.2   17.3        0.7     0.4\n",
       "3  1998  Arkhangelsk Oblast   4.3  10.6   11.7        0.4     0.3\n",
       "4  1998    Astrakhan Oblast   2.9  18.0    9.5        0.8     0.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect first 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aquatic-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>DataType</th>\n",
       "      <th>CountOfNonNulls</th>\n",
       "      <th>CountOfNulls</th>\n",
       "      <th>PercentOfNullsIinColumn</th>\n",
       "      <th>PercentOfNullsInData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>int64</td>\n",
       "      <td>1615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>region</td>\n",
       "      <td>object</td>\n",
       "      <td>1615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine</td>\n",
       "      <td>float64</td>\n",
       "      <td>1552</td>\n",
       "      <td>63</td>\n",
       "      <td>3.900929</td>\n",
       "      <td>20.257235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beer</td>\n",
       "      <td>float64</td>\n",
       "      <td>1557</td>\n",
       "      <td>58</td>\n",
       "      <td>3.591331</td>\n",
       "      <td>18.649518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vodka</td>\n",
       "      <td>float64</td>\n",
       "      <td>1554</td>\n",
       "      <td>61</td>\n",
       "      <td>3.777090</td>\n",
       "      <td>19.614148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>champagne</td>\n",
       "      <td>float64</td>\n",
       "      <td>1552</td>\n",
       "      <td>63</td>\n",
       "      <td>3.900929</td>\n",
       "      <td>20.257235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brandy</td>\n",
       "      <td>float64</td>\n",
       "      <td>1549</td>\n",
       "      <td>66</td>\n",
       "      <td>4.086687</td>\n",
       "      <td>21.221865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature DataType  CountOfNonNulls  CountOfNulls  PercentOfNullsIinColumn  \\\n",
       "0       year    int64             1615             0                 0.000000   \n",
       "1     region   object             1615             0                 0.000000   \n",
       "2       wine  float64             1552            63                 3.900929   \n",
       "3       beer  float64             1557            58                 3.591331   \n",
       "4      vodka  float64             1554            61                 3.777090   \n",
       "5  champagne  float64             1552            63                 3.900929   \n",
       "6     brandy  float64             1549            66                 4.086687   \n",
       "\n",
       "   PercentOfNullsInData  \n",
       "0              0.000000  \n",
       "1              0.000000  \n",
       "2             20.257235  \n",
       "3             18.649518  \n",
       "4             19.614148  \n",
       "5             20.257235  \n",
       "6             21.221865  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for quality issues in data\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quantitative-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>wine</th>\n",
       "      <th>beer</th>\n",
       "      <th>vodka</th>\n",
       "      <th>champagne</th>\n",
       "      <th>brandy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1615.000000</td>\n",
       "      <td>1552.000000</td>\n",
       "      <td>1557.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1552.000000</td>\n",
       "      <td>1549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>5.628144</td>\n",
       "      <td>51.260148</td>\n",
       "      <td>11.818694</td>\n",
       "      <td>1.313177</td>\n",
       "      <td>0.526998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.478922</td>\n",
       "      <td>2.813208</td>\n",
       "      <td>25.372821</td>\n",
       "      <td>5.128806</td>\n",
       "      <td>0.797956</td>\n",
       "      <td>0.400201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>3.575000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>49.970000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.377500</td>\n",
       "      <td>67.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.665000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>207.300000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year         wine         beer        vodka    champagne  \\\n",
       "count  1615.000000  1552.000000  1557.000000  1554.000000  1552.000000   \n",
       "mean   2007.000000     5.628144    51.260148    11.818694     1.313177   \n",
       "std       5.478922     2.813208    25.372821     5.128806     0.797956   \n",
       "min    1998.000000     0.100000     0.400000     0.050000     0.100000   \n",
       "25%    2002.000000     3.575000    32.400000     8.300000     0.800000   \n",
       "50%    2007.000000     5.400000    49.970000    11.500000     1.200000   \n",
       "75%    2012.000000     7.377500    67.400000    15.000000     1.665000   \n",
       "max    2016.000000    18.100000   207.300000    40.600000     5.560000   \n",
       "\n",
       "            brandy  \n",
       "count  1549.000000  \n",
       "mean      0.526998  \n",
       "std       0.400201  \n",
       "min       0.000000  \n",
       "25%       0.200000  \n",
       "50%       0.400000  \n",
       "75%       0.700000  \n",
       "max       2.300000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics for numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical data\n",
    "df.describe(exclude = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-italic",
   "metadata": {},
   "source": [
    "As can be observed above, the dataset consists of 1615 rows and 7 columns. Region is the only column of type object. Also, we can tell that there are missing values in all the columns containing data of the alcoholic beverages. Noteably, Brandy has the most missing values, about 21.2% of total nulls in data. We will handle missing values in the cleaning and transformation sections. \n",
    "\n",
    "The summary statistics gave us an overview of basic statistical properties. We can tell that the data contains sales per capita records from the 2002 to 1998. There are 85 regions covered and Kamchatka Krai is the most frequent among region values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-white",
   "metadata": {},
   "source": [
    "### Clean and Transform Data\n",
    "\n",
    "The data is relatively clean based on our observation from inspection section. We will handle missing values by imputing the mean of values in each beverage column and also, strip leading and trailing spaces in region column.\n",
    "\n",
    "A function is created to perform the cleaning and transformation processes stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to clean and transform data\n",
    "# def clean_and_transform(data, cols):\n",
    "#     # loop through columns and fillna with mean values\n",
    "#     # strip leading and trailing spaces in text data\n",
    "#     for col in cols:\n",
    "#         if data[col].dtypes == 'int64' or data[col].dtypes == 'int32' or data[col].dtypes == 'float64':\n",
    "#             data[col] = data[col].fillna(data[col].mean())\n",
    "#         elif data[col].dtypes == 'object':\n",
    "#             data[col] = data[col].apply(lambda x: x.strip())\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exclusive-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and transform data\n",
    "df_clean = funcs.clean_and_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caroline-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>wine</th>\n",
       "      <th>beer</th>\n",
       "      <th>vodka</th>\n",
       "      <th>champagne</th>\n",
       "      <th>brandy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>Republic of Adygea</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>Amur Oblast</td>\n",
       "      <td>2.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>Arkhangelsk Oblast</td>\n",
       "      <td>4.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>Astrakhan Oblast</td>\n",
       "      <td>2.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year              region  wine  beer  vodka  champagne  brandy\n",
       "0  1998  Republic of Adygea   1.9   8.8    3.4        0.3     0.1\n",
       "1  1998          Altai Krai   3.3  19.2   11.3        1.1     0.1\n",
       "2  1998         Amur Oblast   2.1  21.2   17.3        0.7     0.4\n",
       "3  1998  Arkhangelsk Oblast   4.3  10.6   11.7        0.4     0.3\n",
       "4  1998    Astrakhan Oblast   2.9  18.0    9.5        0.8     0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data again for quality issues\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-freeware",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Visualizing the data will aid in identifying patterns and relationships among the features. For this project, we will create the following plots:\n",
    "- Time series of sales data.\n",
    "- Regional Sales.\n",
    "- Correlation of numerical features.\n",
    "\n",
    "We will also create a function for some of these plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outdoor-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create time series plots\n",
    "def plot_features(data, grp_v_single_region, grp_v_single_bev):\n",
    "    # aggregate data by year and region\n",
    "    df_grp = data.groupby(['year', 'region'], as_index = False)[['wine', 'beer', 'vodka', 'champagne', 'brandy']].mean()\n",
    "     # melt data frame - wide to long\n",
    "    df_melt = pd.melt(df_grp, id_vars = ['year', 'region'], value_vars = ['wine', 'beer', 'vodka', 'champagne', 'brandy'],\\\n",
    "                         var_name = 'beverages', value_name = 'Sales per Capita')\n",
    "    df_melt['year'] = df_melt['year'].astype('int64')\n",
    "    \n",
    "    # plot time series for all regions and all beverages\n",
    "    if grp_v_single_region == 'all regions' and grp_v_single_bev == 'all beverages':\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(15, 10)\n",
    "        sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "        sns.lineplot(data = df_melt, x = 'year', y = 'Sales per Capita', hue = 'beverages',\\\n",
    "                     style = 'beverages', markers = True)\n",
    "        plt.title(\"Time Series of Mean Sales per Capita for all beverages\")\n",
    "        plt.savefig(\"images/{}_{}_regions\".format(grp_v_single_region.strip(), grp_v_single_bev.strip()))\n",
    "        plt.show()\n",
    "    # plot time series for a region and all beverages\n",
    "    elif grp_v_single_region in df_melt['region'].unique().tolist()\\\n",
    "    and grp_v_single_bev == 'all beverages':\n",
    "        df_plot = df_melt.loc[df_melt['region'] == grp_v_single_region]    \n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(15, 10)\n",
    "        sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "        sns.lineplot(data = df_plot, x = 'year', y = 'Sales per Capita', hue = 'beverages',\\\n",
    "                     style = 'beverages', markers = True)\n",
    "        plt.title(\"Time Series of Mean Sales per Capita of all Beverages in {}\".format(grp_v_single_region))\n",
    "        plt.savefig(\"images/{}_{}_regions\".format(grp_v_single_region.strip(), grp_v_single_bev.strip()))\n",
    "        plt.show()\n",
    "    # plot time series for a region and a beverage\n",
    "    elif grp_v_single_region in df_melt['region'].unique().tolist()\\\n",
    "    and grp_v_single_bev in  df_melt['beverages'].unique().tolist():\n",
    "        df_plot = df_melt.loc[(df_melt['region'] == grp_v_single_region) & (df_melt['beverages'] == grp_v_single_bev)]    \n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(15, 10)\n",
    "        sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "        sns.lineplot(data = df_plot, x = 'year', y = 'Sales per Capita', hue = 'beverages',\\\n",
    "                     style = 'beverages', markers = False)\n",
    "        plt.title(\"Time Series of Mean Sales per Capita of {} in {}\".format(grp_v_single_bev, grp_v_single_region))\n",
    "        plt.savefig(\"images/{}_{}_regions\".format(grp_v_single_region.strip(), grp_v_single_bev.strip()))\n",
    "        plt.show()\n",
    "    # plot time series for all region and a beverage\n",
    "    elif grp_v_single_region == 'all regions' and grp_v_single_bev in  df_melt['beverages'].unique().tolist():\n",
    "        df_plot = df_melt.loc[df_melt['beverages'] == grp_v_single_bev]    \n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(15, 10)\n",
    "        sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "        sns.lineplot(data = df_plot, x = 'year', y = 'Sales per Capita', hue = 'beverages',\\\n",
    "                     style = 'beverages', markers = False)\n",
    "        plt.title(\"Time Series of Mean Sales per Capita of {} in {}\".format(grp_v_single_bev,\\\n",
    "                                                                            grp_v_single_region))\n",
    "        plt.savefig(\"images/{}_{}_regions\".format(grp_v_single_region.strip(), grp_v_single_bev.strip()))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "korean-taste",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('year', 'region')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-aa5216612d1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_grp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_melt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_melt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'region'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Desktop\\gitrepos\\Alcohol-Consumption-in-Russia\\funcs.py\u001b[0m in \u001b[0;36mgroup_melt\u001b[1;34m(df, *args)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgroup_melt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# aggregate data by year and region\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mdf_grp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wine'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'beer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vodka'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'champagne'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'brandy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m      \u001b[1;31m# melt data frame - wide to long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     df_melt = pd.melt(df_grp, id_vars = args, value_vars = ['wine', 'beer', 'vodka', 'champagne', 'brandy'],\\\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   6523\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6524\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6525\u001b[1;33m             \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6526\u001b[0m         )\n\u001b[0;32m   6527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    531\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m             )\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    784\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('year', 'region')"
     ]
    }
   ],
   "source": [
    "df_grp, df_melt = funcs.group_melt(df_clean, 'year', 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nervous-danish",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_melt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5eee9c7903f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Time series beverage sales\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfuncs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_timeseries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_melt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'all regions'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'all beverages'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_melt' is not defined"
     ]
    }
   ],
   "source": [
    "# Time series beverage sales\n",
    "funcs.plot_timeseries(df_melt, 'all regions', 'all beverages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-latin",
   "metadata": {},
   "source": [
    "The time series plot above indicates that beer had the highest sales over year even though sales decreased from 2012 to 2015. On the other hand, our product of interest, wine, saw a gradual increase in sales starting from 2002. Vodka also experienced gradual drop in sales. There is minimal sales increase for champagne and brandy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series for Saint Petersburg\n",
    "plot_features(df_clean, 'Saint Petersburg', 'all beverages')\n",
    "plot_features(df_clean, 'Saint Petersburg', 'wine')\n",
    "# plot_features(df_clean, 'all regions', 'brandy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-brick",
   "metadata": {},
   "source": [
    "Sales in Saint Petersburg follows same trend as combined regions. Zooming in on wine, we can see a leap between 2004 and 2005 followed by fluctuating sales up to 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to explore categorial variables and rank sales\n",
    "def cat_plot(data, plot, **kwargs):\n",
    "    grp_v_single_region = kwargs.get('grp_v_single_region', None)\n",
    "    grp_v_single_bev = kwargs.get('grp_v_single_bev', None)\n",
    "    top = kwargs.get('top', None)\n",
    "    bottom = kwargs.get('bottom', None)\n",
    "    n = kwargs.get('n', None)\n",
    "    # aggregate data by region\n",
    "    df_grp = data.groupby('region', as_index = False)[['wine', 'beer', 'vodka', 'champagne', 'brandy']].mean()\n",
    "     # melt data frame - wide to long\n",
    "    df_melt = pd.melt(df_grp, id_vars =['region'], value_vars = ['wine', 'beer', 'vodka', 'champagne', 'brandy'],\\\n",
    "                         var_name = 'beverages', value_name = 'Sales per Capita')\n",
    "    if plot == 'boxplot':\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(15, 10)\n",
    "        sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "        sns.boxplot(x = 'Sales per Capita', y = 'beverages', data = df_melt)\n",
    "        sns.despine(offset = 20, trim = True)\n",
    "        plt.title('Distribution of Mean Sales per Capita by Beverage')\n",
    "        plt.savefig(\"images/Distribution Plot of Sales by Beverage.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    elif plot == 'catplot':\n",
    "        if (top and n):\n",
    "            sort_df = df_melt.sort_values(by = ['Sales per Capita'], ascending = False)\n",
    "            top_n = sort_df.iloc[:n, :]\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.set_size_inches(15, 10)\n",
    "            sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "            sns.barplot(x = 'Sales per Capita', y = 'region', hue = 'beverages', data = top_n)\n",
    "            sns.despine(offset = 10, trim = True)\n",
    "            plt.title('{} {} Regions by Mean Sales per Capita'.format(top, n))\n",
    "            plt.savefig(\"images/{}_{}_regions.png\".format(top.lower(), n))\n",
    "            plt.show()\n",
    "        elif (bottom and n):\n",
    "            sort_df = df_melt.sort_values(by = ['Sales per Capita'], ascending = True)\n",
    "            bottom_n = sort_df.iloc[:n, :]\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.set_size_inches(15, 10)\n",
    "            sns.set_context('poster', font_scale = 0.5, rc = {'grid.linewidth': 0.5})\n",
    "            sns.barplot(x = 'Sales per Capita', y = 'region', hue = 'beverages', data = bottom_n)\n",
    "            sns.despine(offset = 10, trim = True)\n",
    "            plt.title('{} {} Regions by Mean Sales per Capita'.format(bottom, n))\n",
    "            plt.savefig(\"images/{}_{}_regions\".format(bottom.lower(), n))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top sales by Region\n",
    "cat_plot(df_clean, 'catplot', top = 'Top', n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-constitution",
   "metadata": {},
   "source": [
    "Looking at location sales, Saint Pertersgburg tops the list followed by Moscow and Yamalo-Nenets Autonomous Okrug in third. As observed in the time series plot, beer has the most sales by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot of beverages\n",
    "cat_plot(df_clean, 'boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-thickness",
   "metadata": {},
   "source": [
    "The boxplot shows the distribution of sales per beverage. There are three regions in beer sales that are outliers outliers while you can observe 2 outlier regions in wine sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a correlation heat map of numerical values\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 8)\n",
    "mask = np.triu(np.ones_like(df_clean.corr(), dtype = bool))\n",
    "heatmap = sns.heatmap(df_clean.corr(), mask = mask, vmin = -1, vmax = 1, annot  =True, cmap = 'GnBu')\n",
    "heatmap.set_title(\"Correlation Heatmap of Beverage Sales\", fontdict = {'fontsize': 16}, pad = 15)\n",
    "plt.setp(ax.get_xticklabels(), rotation = 90)\n",
    "plt.setp(ax.get_yticklabels(), rotation = 0)\n",
    "plt.savefig(\"images/dfcorr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-announcement",
   "metadata": {},
   "source": [
    "The correlation heatmap shows a strong positive relationship between brandy and champagne sales. This signifies that for every increase in one variable, there's a corresponding increase in sales of the other variable. We can also observe positive relationship between wine and brandy sales, even though not as strong as relationship between champagne and brandy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-blanket",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "This section will aim to solve the main ask of this project. We will use **Collaborative Filtering Method**, an unsupervised machine learning algorithm to recommend regions similar to wine sales in Saint Petersburg. \n",
    "\n",
    "**Collaborative Filtering Method** is one of three major methods to build a Recommender System. This method uses a similarity score to recommend items based on user interactions (Source: [Recommendation System for Streaming Platforms](https://www.datacamp.com/community/tutorials/streaming-platform-analysis)). \n",
    "\n",
    "The following steps will be implemented:\n",
    "\n",
    "- Import machine learning modules\n",
    "- Preprocess data for machine learning\n",
    "- Compute similarity score using cosine similarity\n",
    "\n",
    "We will create functions to preprocess the data and compute similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-bradford",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We will scale numerical features using MinMaxScaler to have numerical values between 0 and 1. Year column will be converted to object data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "def preprocess_data(df):\n",
    "    # instantiate MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    \n",
    "    # convert year to object data type\n",
    "    df['year'] = df['year'].astype('object')\n",
    "    \n",
    "    # aggregate data by region\n",
    "    df_grp = df.groupby('region', as_index = False)[['wine', 'beer', 'vodka', 'champagne', 'brandy']].mean()\n",
    "\n",
    "    # create dataframe of transformed features\n",
    "    df_grp[['wine', 'beer', 'vodka', 'champagne', 'brandy']] = scaler.fit_transform(df_grp[['wine', 'beer', 'vodka', 'champagne', 'brandy']])\n",
    "    \n",
    "    # extract numerical data\n",
    "    df_nums = df_grp[['wine', 'beer', 'vodka', 'champagne', 'brandy']]\n",
    "    # extract numerical columns names\n",
    "    df_num_cols = df_nums.columns.tolist()\n",
    "    \n",
    "    # extract all columns\n",
    "    cols_of_df = df.columns.tolist()\n",
    "    \n",
    "    return df_grp, cols_of_df, df_nums, df_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-employer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df, features, scaled_num_df, scaled_num_df_cols = preprocess_data(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cosine similarity\n",
    "cos_sim = cosine_similarity(scaled_num_df, scaled_num_df)\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping of indices and region names\n",
    "indices = pd.Series(scaled_df.index, index = scaled_df['region'])\n",
    "indices = indices.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index corresponding to region\n",
    "idx = indices['Saint Petersburg']\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pairwise similarity scores\n",
    "sig_scores = list(enumerate(cos_sim[idx]))\n",
    "# sig_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the regions\n",
    "sig_scores = sorted(sig_scores, key = lambda x: x[1], reverse = True)\n",
    "# sig_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of 10 most similar regions\n",
    "sig_scores = sig_scores[1:11]\n",
    "sig_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region indices\n",
    "region_indices = [i[0] for i in sig_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 most similar regions\n",
    "scaled_df['region'].iloc[region_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_regions(df, region, n, **kwargs):\n",
    "\n",
    "    grp_v_single_beverages = kwargs.get('grp_v_single_beverages', None)\n",
    "    \n",
    "    df_grp, cols_of_df, df_nums, df_num_cols = preprocess_data(df)\n",
    "    \n",
    "    # compute the cosine similarity\n",
    "    cos_sim = cosine_similarity(df_nums, df_nums)\n",
    "    # reverse mapping of indices and region names\n",
    "    indices = pd.Series(scaled_df.index, index = df_grp['region'])\n",
    "    indices = indices.drop_duplicates()\n",
    "    # get index corresponding to region\n",
    "    idx = indices[region]\n",
    "    # get pairwise similarity scores\n",
    "    sig_scores = list(enumerate(cos_sim[idx]))\n",
    "    # sort the regions\n",
    "    sig_scores = sorted(sig_scores, key = lambda x: x[1], reverse = True)\n",
    "    # scores of n most similar regions\n",
    "    sig_scores = sig_scores[1:n+1]\n",
    "    # region indices\n",
    "    region_indices = [i[0] for i in sig_scores]\n",
    "    # get n most similar regions\n",
    "    top_n = df_grp['region'].iloc[region_indices]\n",
    "    \n",
    "    # generate scores for a single beverage\n",
    "    if grp_v_single_beverages:\n",
    "        df_grp_bev = df_nums[grp_v_single_beverages]\n",
    "        # compute the cosine similarity\n",
    "        cos_sim = cosine_similarity(df_grp_bev, df_grp_bev)\n",
    "        # reverse mapping of indices and region names\n",
    "        indices = pd.Series(scaled_df.index, index = df_grp['region'])\n",
    "        indices = indices.drop_duplicates()\n",
    "        # get index corresponding to region\n",
    "        idx = indices[region]\n",
    "        # get pairwise similarity scores\n",
    "        sig_scores = list(enumerate(cos_sim[idx]))\n",
    "        # sort the regions\n",
    "        sig_scores = sorted(sig_scores, key = lambda x: x[1], reverse = True)\n",
    "        # scores of n most similar regions\n",
    "        sig_scores = sig_scores[1:n+1]\n",
    "        # region indices\n",
    "        region_indices = [i[0] for i in sig_scores]\n",
    "        # get n most similar regions\n",
    "        top_n = df_grp['region'].iloc[region_indices]\n",
    "    \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_regions(df_clean, 'Saint Petersburg', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythonadv] *",
   "language": "python",
   "name": "conda-env-pythonadv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
